<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Kenneth Benoit" />


<title>textmodel Performance Comparisons</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">textmodel Performance Comparisons</h1>
<h4 class="author">Kenneth Benoit</h4>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(<span class="st">&quot;quanteda.core&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co">## Package version: 2.1.1</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">## Parallel computing: 2 of 8 threads used.</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co">## See https://quanteda.io for tutorials and examples.</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="kw">library</span>(<span class="st">&quot;quanteda.textmodels&quot;</span>)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">## </span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">## Attaching package: &#39;quanteda.textmodels&#39;</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">## The following object is masked from &#39;package:quanteda.core&#39;:</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co">## </span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co">##     data_dfm_lbgexample</span></span></code></pre></div>
<div id="naive-bayes" class="section level2">
<h2>Naive Bayes</h2>
<p><strong>quanteda.textmodels</strong> implements fast methods for fitting and predicting Naive Bayes textmodels built especially for sparse document-feature matrices from textual data. It implements two models: multinomial and Bernoulli. (See Manning, Raghavan, and Schütze 2008, Chapter 13.)</p>
<p>Here, we compare performance for the two models, and then to the performance from two other packages for fitting these models.</p>
<p>For these tests, we will choose the dataset of 50,000 movie reviews from Maas et. al. (2011). We will use their partition into test and training sets for training and fitting our models.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># large movie review database of 50,000 movie reviews</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="kw">load</span>(<span class="kw">url</span>(<span class="st">&quot;https://www.dropbox.com/s/sjdfmx8ggwfda5o/data_corpus_LMRD.rda?dl=1&quot;</span>))</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a>dfmat &lt;-<span class="st"> </span><span class="kw">dfm</span>(data_corpus_LMRD)</span>
<span id="cb2-5"><a href="#cb2-5"></a>dfmat_train &lt;-<span class="st"> </span><span class="kw">dfm_subset</span>(dfmat, set <span class="op">==</span><span class="st"> &quot;train&quot;</span>)</span>
<span id="cb2-6"><a href="#cb2-6"></a>dfmat_test &lt;-<span class="st"> </span><span class="kw">dfm_subset</span>(dfmat, set <span class="op">==</span><span class="st"> &quot;test&quot;</span>)</span></code></pre></div>
<p>Comparing the performance of fitting the model:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">library</span>(<span class="st">&quot;microbenchmark&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="kw">microbenchmark</span>(</span>
<span id="cb3-3"><a href="#cb3-3"></a>    <span class="dt">multi =</span> <span class="kw">textmodel_nb</span>(dfmat_train, dfmat_train<span class="op">$</span>polarity, <span class="dt">distribution =</span> <span class="st">&quot;multinomial&quot;</span>),</span>
<span id="cb3-4"><a href="#cb3-4"></a>    <span class="dt">bern =</span> <span class="kw">textmodel_nb</span>(dfmat_train, dfmat_train<span class="op">$</span>polarity, <span class="dt">distribution =</span> <span class="st">&quot;Bernoulli&quot;</span>),</span>
<span id="cb3-5"><a href="#cb3-5"></a>    <span class="dt">times =</span> <span class="dv">50</span></span>
<span id="cb3-6"><a href="#cb3-6"></a>)</span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co">## Unit: milliseconds</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co">##   expr      min        lq     mean    median       uq      max neval cld</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co">##  multi 87.93687  90.29019 102.3266  91.53301 100.0859 188.5612    50  a </span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="co">##   bern 99.44716 102.81609 119.8554 105.97683 137.6080 180.9268    50   b</span></span></code></pre></div>
<p>And for prediction:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">microbenchmark</span>(</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="dt">multi =</span> <span class="kw">predict</span>(<span class="kw">textmodel_nb</span>(dfmat_train, dfmat_train<span class="op">$</span>polarity, <span class="dt">distribution =</span> <span class="st">&quot;multinomial&quot;</span>),</span>
<span id="cb4-3"><a href="#cb4-3"></a>                    <span class="dt">newdata =</span> dfmat_test),</span>
<span id="cb4-4"><a href="#cb4-4"></a>    <span class="dt">bern =</span> <span class="kw">predict</span>(<span class="kw">textmodel_nb</span>(dfmat_train, dfmat_train<span class="op">$</span>polarity, <span class="dt">distribution =</span> <span class="st">&quot;Bernoulli&quot;</span>),</span>
<span id="cb4-5"><a href="#cb4-5"></a>                   <span class="dt">newdata =</span> dfmat_test),</span>
<span id="cb4-6"><a href="#cb4-6"></a>    <span class="dt">times =</span> <span class="dv">50</span></span>
<span id="cb4-7"><a href="#cb4-7"></a>)</span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="co">## Unit: milliseconds</span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="co">##   expr      min       lq     mean   median       uq      max neval cld</span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="co">##  multi 107.5014 111.3280 133.1211 121.5560 146.9285 242.0176    50  a </span></span>
<span id="cb4-11"><a href="#cb4-11"></a><span class="co">##   bern 152.1369 160.8652 215.0651 204.4227 248.6259 515.2699    50   b</span></span></code></pre></div>
<p>Now let’s see how <code>textmodel_nb()</code> compares to equivalent functions from other packages. Multinomial:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">library</span>(<span class="st">&quot;fastNaiveBayes&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="kw">library</span>(<span class="st">&quot;naivebayes&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co">## naivebayes 0.9.7 loaded</span></span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="kw">microbenchmark</span>(</span>
<span id="cb5-6"><a href="#cb5-6"></a>    <span class="dt">textmodels =</span> {</span>
<span id="cb5-7"><a href="#cb5-7"></a>      tmod &lt;-<span class="st">  </span><span class="kw">textmodel_nb</span>(dfmat_train, dfmat_train<span class="op">$</span>polarity, <span class="dt">smooth =</span> <span class="dv">1</span>, <span class="dt">distribution =</span> <span class="st">&quot;multinomial&quot;</span>)</span>
<span id="cb5-8"><a href="#cb5-8"></a>      pred &lt;-<span class="st"> </span><span class="kw">predict</span>(tmod, <span class="dt">newdata =</span> dfmat_test)</span>
<span id="cb5-9"><a href="#cb5-9"></a>    },</span>
<span id="cb5-10"><a href="#cb5-10"></a>    <span class="dt">fastNaiveBayes =</span> { </span>
<span id="cb5-11"><a href="#cb5-11"></a>      tmod &lt;-<span class="st"> </span><span class="kw">fnb.multinomial</span>(<span class="kw">as</span>(dfmat_train, <span class="st">&quot;dgCMatrix&quot;</span>), <span class="dt">y =</span> dfmat_train<span class="op">$</span>polarity, <span class="dt">laplace =</span> <span class="dv">1</span>, <span class="dt">sparse =</span> <span class="ot">TRUE</span>)</span>
<span id="cb5-12"><a href="#cb5-12"></a>      pred &lt;-<span class="st"> </span><span class="kw">predict</span>(tmod, <span class="dt">newdata =</span> <span class="kw">as</span>(dfmat_test, <span class="st">&quot;dgCMatrix&quot;</span>))</span>
<span id="cb5-13"><a href="#cb5-13"></a>    },</span>
<span id="cb5-14"><a href="#cb5-14"></a>    <span class="dt">naivebayes =</span> {</span>
<span id="cb5-15"><a href="#cb5-15"></a>      tmod =<span class="st"> </span><span class="kw">multinomial_naive_bayes</span>(<span class="kw">as</span>(dfmat_train, <span class="st">&quot;dgCMatrix&quot;</span>), dfmat_train<span class="op">$</span>polarity, <span class="dt">laplace =</span> <span class="dv">1</span>)</span>
<span id="cb5-16"><a href="#cb5-16"></a>      pred &lt;-<span class="st"> </span><span class="kw">predict</span>(tmod, <span class="dt">newdata =</span> <span class="kw">as</span>(dfmat_test, <span class="st">&quot;dgCMatrix&quot;</span>))</span>
<span id="cb5-17"><a href="#cb5-17"></a>    },</span>
<span id="cb5-18"><a href="#cb5-18"></a>    <span class="dt">times =</span> <span class="dv">50</span></span>
<span id="cb5-19"><a href="#cb5-19"></a>)</span>
<span id="cb5-20"><a href="#cb5-20"></a><span class="co">## Unit: milliseconds</span></span>
<span id="cb5-21"><a href="#cb5-21"></a><span class="co">##            expr      min       lq     mean   median       uq      max neval cld</span></span>
<span id="cb5-22"><a href="#cb5-22"></a><span class="co">##      textmodels 105.7772 109.7809 120.8084 113.5183 119.9896 184.2289    50 a  </span></span>
<span id="cb5-23"><a href="#cb5-23"></a><span class="co">##  fastNaiveBayes 191.4640 206.0136 247.7814 228.6368 259.4799 449.7987    50   c</span></span>
<span id="cb5-24"><a href="#cb5-24"></a><span class="co">##      naivebayes 163.0109 168.5087 199.7361 179.7997 207.4047 487.9898    50  b</span></span></code></pre></div>
<p>And Bernoulli. Note here that while we are supplying the boolean matrix to <code>textmodel_nb()</code>, this re-weighting from the count matrix would have been performed automatically within the function had we not done so in advance - it’s done here just for comparison.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>dfmat_train_bern &lt;-<span class="st"> </span><span class="kw">dfm_weight</span>(dfmat_train, <span class="dt">scheme =</span> <span class="st">&quot;boolean&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a>dfmat_test_bern &lt;-<span class="st"> </span><span class="kw">dfm_weight</span>(dfmat_test, <span class="dt">scheme =</span> <span class="st">&quot;boolean&quot;</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="kw">microbenchmark</span>(</span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span class="dt">textmodels =</span> {</span>
<span id="cb6-6"><a href="#cb6-6"></a>      tmod &lt;-<span class="st">  </span><span class="kw">textmodel_nb</span>(dfmat_train_bern, dfmat_train<span class="op">$</span>polarity, <span class="dt">smooth =</span> <span class="dv">1</span>, <span class="dt">distribution =</span> <span class="st">&quot;Bernoulli&quot;</span>)</span>
<span id="cb6-7"><a href="#cb6-7"></a>      pred &lt;-<span class="st"> </span><span class="kw">predict</span>(tmod, <span class="dt">newdata =</span> dfmat_test)</span>
<span id="cb6-8"><a href="#cb6-8"></a>    },</span>
<span id="cb6-9"><a href="#cb6-9"></a>    <span class="dt">fastNaiveBayes =</span> { </span>
<span id="cb6-10"><a href="#cb6-10"></a>      tmod &lt;-<span class="st"> </span><span class="kw">fnb.bernoulli</span>(<span class="kw">as</span>(dfmat_train_bern, <span class="st">&quot;dgCMatrix&quot;</span>), <span class="dt">y =</span> dfmat_train<span class="op">$</span>polarity, <span class="dt">laplace =</span> <span class="dv">1</span>, <span class="dt">sparse =</span> <span class="ot">TRUE</span>)</span>
<span id="cb6-11"><a href="#cb6-11"></a>      pred &lt;-<span class="st"> </span><span class="kw">predict</span>(tmod, <span class="dt">newdata =</span> <span class="kw">as</span>(dfmat_test_bern, <span class="st">&quot;dgCMatrix&quot;</span>))</span>
<span id="cb6-12"><a href="#cb6-12"></a>    },</span>
<span id="cb6-13"><a href="#cb6-13"></a>    <span class="dt">naivebayes =</span> {</span>
<span id="cb6-14"><a href="#cb6-14"></a>      tmod =<span class="st"> </span><span class="kw">bernoulli_naive_bayes</span>(<span class="kw">as</span>(dfmat_train_bern, <span class="st">&quot;dgCMatrix&quot;</span>), dfmat_train<span class="op">$</span>polarity, <span class="dt">laplace =</span> <span class="dv">1</span>)</span>
<span id="cb6-15"><a href="#cb6-15"></a>      pred &lt;-<span class="st"> </span><span class="kw">predict</span>(tmod, <span class="dt">newdata =</span> <span class="kw">as</span>(dfmat_test_bern, <span class="st">&quot;dgCMatrix&quot;</span>))</span>
<span id="cb6-16"><a href="#cb6-16"></a>    },</span>
<span id="cb6-17"><a href="#cb6-17"></a>    <span class="dt">times =</span> <span class="dv">50</span></span>
<span id="cb6-18"><a href="#cb6-18"></a>)</span>
<span id="cb6-19"><a href="#cb6-19"></a><span class="co">## Unit: milliseconds</span></span>
<span id="cb6-20"><a href="#cb6-20"></a><span class="co">##            expr      min       lq     mean   median       uq      max neval cld</span></span>
<span id="cb6-21"><a href="#cb6-21"></a><span class="co">##      textmodels 152.8912 156.7809 183.5844 178.7556 198.6790 288.4496    50 a  </span></span>
<span id="cb6-22"><a href="#cb6-22"></a><span class="co">##  fastNaiveBayes 210.5292 224.1488 269.1907 265.2714 285.3515 538.8882    50   c</span></span>
<span id="cb6-23"><a href="#cb6-23"></a><span class="co">##      naivebayes 177.8537 185.0257 211.3678 202.3064 232.2232 348.2674    50  b</span></span></code></pre></div>
<p>😎</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Maas, Andrew L., Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts (2011). “Learning Word Vectors for Sentiment Analysis”. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).</p>
<p>Majka M (2020). <em>naivebayes: High Performance Implementation of the Naive Bayes Algorithm in R</em>. R package version 0.9.7, &lt;URL: <a href="https://CRAN.R-project.org/package=naivebayes" class="uri">https://CRAN.R-project.org/package=naivebayes</a>&gt;. Date: 2020-03-08.</p>
<p>Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze (2008). <em>Introduction to Information Retrieval</em>. Cambridge University Press.</p>
<p>Skogholt, Martin (2020). <em>fastNaiveBayes: Extremely Fast Implementation of a Naive Bayes Classifier</em>. R package version 2.2.0. <a href="https://github.com/mskogholt/fastNaiveBayes" class="uri">https://github.com/mskogholt/fastNaiveBayes</a>. Date: 2020-02-23.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
